{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as integrate\n",
    "import random\n",
    "\n",
    "import synchrony.PlottingTools as plottingTools\n",
    "from synchrony.ParameterSet import ParameterSet\n",
    "import synchrony.DataStorage as dataStorage\n",
    "import synchrony.DataAnalysis as dataAnalysis\n",
    "import synchrony.MakeDataframe as makeDataframe\n",
    "from synchrony import mainClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path /home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b\n",
      "parameter_path /home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/parameter_set.csv\n"
     ]
    }
   ],
   "source": [
    "file_path_input_params_json = '../input_params.json'\n",
    "input_param_dict = mainClass.extract_variables_from_input_params_json(file_path_input_params_json)\n",
    "root_path = input_param_dict[\"DATA_FOLDER_PATH\"]\n",
    "simulation_location = 'Paper/Fig_03/Fig_3b' #'Paper/X_Appendix/A4_higher_firing_rate/A4c' #'Paper/X_Appendix/A4_higher_firing_rate/A4c' or 'Paper/Fig_4/Fig_4bc'\n",
    "file_path = os.path.join(root_path, simulation_location)\n",
    "print('file_path', file_path)\n",
    "parameter_path = os.path.join(file_path, 'parameter_set.csv')\n",
    "print('parameter_path', parameter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinkish_red = (247 / 255, 109 / 255, 109 / 255)\n",
    "green = (0 / 255, 133 / 255, 86 / 255)\n",
    "dark_blue = (36 / 255, 49 / 255, 94 / 255)\n",
    "light_blue = (168 / 255, 209 / 255, 231 / 255)\n",
    "blue = (55 / 255, 71 / 255, 133 / 255)\n",
    "yellow = (247 / 255, 233 / 255, 160 / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/mean_time_interval_CV.pdf',\n",
      " '/home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/CV_with_cell_cycle_5000.pdf',\n",
      " '/home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/CV.pdf',\n",
      " '/home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/8435_vary_hill_Elf_no_time_traces',\n",
      " '/home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/v_init_mean.pdf',\n",
      " '/home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/CV_with_cell_cycle_short.pdf',\n",
      " '/home/berger/Data/Synchrony/Paper/Fig_03/Fig_3b/mean_time_interval.pdf']\n"
     ]
    }
   ],
   "source": [
    "data_frame = makeDataframe.make_dataframe(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 15\n",
    "N_max = 2000\n",
    "\n",
    "# if simulation_location == 'Paper/X_Appendix/A4_higher_firing_rate/A4c':\n",
    "#     Vb= data_frame[\"v_birth_th\"][0] / data_frame[\"n_ori_birth\"][0] * 0.53\n",
    "# elif simulation_location == 'Paper/Fig_4/Fig_4bc':\n",
    "    \n",
    "Vb= data_frame[\"v_birth_th\"][0] / data_frame[\"n_ori_birth\"][0]\n",
    "# else:\n",
    "#     print(\"problem with file directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations to obtain average time intervall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_max_rate_given_n_eff(n, growth_rate, v_init, v_b):\n",
    "    return n*growth_rate * np.log(2)/np.log((2 * v_init**n)/(v_b**n+v_init**n))\n",
    "\n",
    "def calculate_approx_opening_prob_of_time(t, rate_growth, v_birth, hill_coeff_eff, crit_vol):\n",
    "    vol= v_birth * np.exp(rate_growth*t)\n",
    "    return vol**hill_coeff_eff/(vol**hill_coeff_eff+ crit_vol**hill_coeff_eff)\n",
    "\n",
    "def calculate_whether_initiate(rate, time_step):\n",
    "    prob = rate * time_step\n",
    "    random_number = random.random()\n",
    "    return prob >= random_number\n",
    "\n",
    "def make_list_intervals_new(t_max, time_step, rate_growth, v_birth, hill_coeff_eff, crit_vol, firing_rate_0):\n",
    "    n_simu = 2000\n",
    "    list_t_init_tupel = []\n",
    "    time = np.arange(0, t_max, time_step)\n",
    "    approx_opening_probability_of_time = calculate_approx_opening_prob_of_time(time, rate_growth, v_birth, hill_coeff_eff, crit_vol)\n",
    "    for simu_i in range(0, n_simu):\n",
    "        init_events = []\n",
    "        for n in range(0,2):\n",
    "            for n_step in range(1, time.size): # start at one because 0 is the initial condition\n",
    "                if calculate_whether_initiate(firing_rate_0 * approx_opening_probability_of_time[n_step], time_step):\n",
    "                    init_events.append(time[n_step])\n",
    "                    break\n",
    "        list_t_init_tupel.append(init_events)\n",
    "    delta_t = [abs(item[1]-item[0]) for item in list_t_init_tupel]\n",
    "    return delta_t\n",
    "\n",
    "def make_list_intervals_double_function(t_max, time_step, rate_growth, v_birth, hill_activation_potential, hill_origin_opening, v_init_th, f_crit, firing_rate_0):\n",
    "    n_simu = 2000\n",
    "    list_t_init_tupel = []\n",
    "    time = np.arange(0, t_max, time_step)\n",
    "    volume = v_birth * np.exp(time * rate_growth)\n",
    "    activation_potential = 1/(1 + (v_init_th / volume)** hill_activation_potential)\n",
    "    origin_opening_prob = 1/(1+(f_crit / activation_potential)**hill_origin_opening)\n",
    "#     approx_opening_probability_of_time = calculate_approx_opening_prob_of_time(time, rate_growth, v_birth, hill_coeff_eff, crit_vol)\n",
    "    for simu_i in range(0, n_simu):\n",
    "        init_events = []\n",
    "        for n in range(0,2):\n",
    "            for n_step in range(1, time.size): # start at one because 0 is the initial condition\n",
    "                if calculate_whether_initiate(firing_rate_0 * origin_opening_prob[n_step], time_step):\n",
    "                    init_events.append(time[n_step])\n",
    "                    break\n",
    "        list_t_init_tupel.append(init_events)\n",
    "    delta_t = [abs(item[1]-item[0]) for item in list_t_init_tupel]\n",
    "    return delta_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the average time intervall between two initiation events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as sc\n",
    "\n",
    "def calculate_survival_probability_indefinite(time_, growth_rate_, effective_hill_coeff_, v_init_, V_b_, firing_rate_0_):\n",
    "    return np.exp(- firing_rate_0_ / (growth_rate_ * effective_hill_coeff_) \n",
    "                  * np.log(v_init_**effective_hill_coeff_ + (V_b_ * np.exp(growth_rate_ * time_))**effective_hill_coeff_))\n",
    "\n",
    "def calculate_survival_probability_definite(time_, t_0_, growth_rate_, effective_hill_coeff_, v_init_, V_b_, firing_rate_0_):\n",
    "    return np.exp(- firing_rate_0_ / (growth_rate_ * effective_hill_coeff_) \n",
    "                  * np.log((v_init_**effective_hill_coeff_ + (V_b_ * np.exp(growth_rate_ * time_))**effective_hill_coeff_)/(v_init_**effective_hill_coeff_ + (V_b_ * np.exp(growth_rate_ * t_0_))**effective_hill_coeff_)))\n",
    "\n",
    "\n",
    "def w_t_indef(time_, t_0_, growth_rate_, effective_hill_coeff_, v_init_, V_b_, firing_rate_0_):\n",
    "    vol = V_b_ * np.exp(growth_rate_* time_)\n",
    "    prefactor = firing_rate_0_ * vol**effective_hill_coeff_ / (vol**effective_hill_coeff_ + v_init_**effective_hill_coeff_ )\n",
    "    return prefactor * calculate_survival_probability_definite(time_, \n",
    "                                                                 t_0_,\n",
    "                                                                 growth_rate_, \n",
    "                                                                 effective_hill_coeff_, \n",
    "                                                                 v_init_, \n",
    "                                                                 V_b_,\n",
    "                                                                 firing_rate_0_)\n",
    "\n",
    "def double_integrate_two_events(growth_rate_, v_init_, V_b_, n_, rate, t_d_):\n",
    "    f = lambda t2, t1, growth_rate, v_init, V_b, n, k_0: w_t_indef(t1, 0, growth_rate, n, v_init, V_b, rate) * w_t_indef(t2, 0,  growth_rate, n, v_init, V_b, rate) * abs(t1-t2)\n",
    "    #factor(growth_rate, v_init, V_b, n, 2 * k_0, t1) * factor(growth_rate, v_init, V_b, n, k_0, t2) * (t2-t1)\n",
    "    return integrate.dblquad(f, 0, t_d_, 0, t_d_, args=(growth_rate_, \n",
    "                                                         v_init_, \n",
    "                                                         V_b_, \n",
    "                                                         n_, \n",
    "                                                         rate,))[0]\n",
    "\n",
    "def double_integrate_two_events_v2(growth_rate_, v_init_, V_b_, n_, rate, t_d_):\n",
    "    f = lambda t2, t1, growth_rate, v_init, V_b, n, k_0: w_t_indef(t1, 0,  growth_rate, n, v_init, V_b, 2*rate) * w_t_indef(t2, t1, growth_rate, n, v_init, V_b, rate) * (t2-t1)\n",
    "    #factor(growth_rate, v_init, V_b, n, 2 * k_0, t1) * factor(growth_rate, v_init, V_b, n, k_0, t2) * (t2-t1)\n",
    "    return integrate.dblquad(f, 0, t_d_, lambda t1: t1, t_d_, args=(growth_rate_, \n",
    "                                                         v_init_, \n",
    "                                                         V_b_, \n",
    "                                                         n_, \n",
    "                                                         rate,))[0]\n",
    "def w_t_simple(time_, rate_):\n",
    "    return rate_ * np.exp(- rate_ * time_)\n",
    "\n",
    "def double_integrate_two_events_simple(rate, t_d_):\n",
    "    f = lambda t2, t1, rate: w_t_simple(t1, rate) * w_t_simple(t2, rate) * abs(t2-t1)\n",
    "    #factor(growth_rate, v_init, V_b, n, 2 * k_0, t1) * factor(growth_rate, v_init, V_b, n, k_0, t2) * (t2-t1)\n",
    "    return integrate.dblquad(f, 0, t_d_, 0, t_d_, args=(rate,))[0]\n",
    "\n",
    "def double_integrate_two_events_simple_2(rate, t_d_):\n",
    "    f = lambda t2, t1, rate: w_t_simple(t1, 2* rate) * w_t_simple(t2, rate) * (t2-t1)\n",
    "    #factor(growth_rate, v_init, V_b, n, 2 * k_0, t1) * factor(growth_rate, v_init, V_b, n, k_0, t2) * (t2-t1)\n",
    "    return integrate.dblquad(f, 0, t_d_,  lambda t1: t1, t_d_, args=(rate,))[0]\n",
    "\n",
    "def integrate_mean_time(growth_rate_, v_init_, V_b_, n_, k_0_, t_d_):\n",
    "    f = lambda t1, growth_rate, v_init, V_b, n, k_0: w_t_indef(t1, 0, growth_rate, n, v_init, V_b, k_0) * t1\n",
    "    return integrate.quad(f, 0, t_d_, args=(growth_rate_, \n",
    "                                                         v_init_, \n",
    "                                                         V_b_, \n",
    "                                                         n_, \n",
    "                                                         k_0_,))[0]\n",
    "\n",
    "def integrate_inner_conditional_time(growth_rate_, v_init_, V_b_, n_, k_0_, t_d_, t1):\n",
    "    f = lambda t2, growth_rate, v_init, V_b, n, k_0, t1: w_t_indef(t2, 0,  growth_rate, n, v_init, V_b, k_0) * (t2-t1)\n",
    "    return integrate.quad(f, t1, t_d_, args=(growth_rate_, \n",
    "                                                         v_init_, \n",
    "                                                         V_b_, \n",
    "                                                         n_, \n",
    "                                                         k_0_,\n",
    "                                                     t1,))[0]\n",
    "\n",
    "def average_asynch_time_cell_cycle_simu(row):\n",
    "    dataframe_time_traces = pd.read_hdf(row.path_dataset, key='dataset_time_traces')\n",
    "    dataframe_division_events = pd.read_hdf(row.path_dataset, key='dataset_div_events')\n",
    "    V_d = dataframe_division_events['v_d']\n",
    "    n_oris = dataframe_time_traces['n_ori']\n",
    "    n_oris_synchr = n_oris[(n_oris ==2.0) | (n_oris ==4.0) | (n_oris ==8.0) | (n_oris ==16.0)]\n",
    "    n_oris_2 = n_oris[(n_oris ==2.0)]\n",
    "    n_oris_4 = n_oris[(n_oris ==4.0)]\n",
    "    fraction_asynch = (n_oris.size - n_oris_synchr.size) / n_oris.size\n",
    "    print('fraction asynch', fraction_asynch)\n",
    "    print('fraction 2', n_oris_2.size/ n_oris.size)\n",
    "    print('fraction 4', n_oris_4.size/ n_oris.size)\n",
    "    time_asynchronous = fraction_asynch / row.doubling_rate * 60\n",
    "    return time_asynchronous\n",
    "\n",
    "def calculate_CV_theoretical(growth_rate_, v_init_, V_b_, n_, rate, t_d_):\n",
    "    \n",
    "    f = lambda t1, growth_rate, v_init, V_b, n, k_0: w_t_indef(t1, 0, growth_rate, n, v_init, V_b, rate) * (V_b * np.exp(growth_rate * t1))\n",
    "    f2 = lambda t1, growth_rate, v_init, V_b, n, k_0: w_t_indef(t1, 0, growth_rate, n, v_init, V_b, rate) * (V_b * np.exp(growth_rate * t1))**2\n",
    "    mean = integrate.quad(f, 0, t_d_, args=(growth_rate_, \n",
    "                                                         v_init_, \n",
    "                                                         V_b_, \n",
    "                                                         n_, \n",
    "                                                         rate,))[0]\n",
    "    second_moment = integrate.quad(f2, 0, t_d_, args=(growth_rate_, \n",
    "                                                         v_init_, \n",
    "                                                         V_b_, \n",
    "                                                         n_, \n",
    "                                                         rate,))[0]\n",
    "    print(np.sqrt(second_moment - mean**2), mean)\n",
    "    return np.sqrt(second_moment - mean**2)/mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame.loc[:, 'n_eff'] = data_frame.apply(lambda row:row.hill_activation_potential * row.hill_origin_opening /2\n",
    "#                                   , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame['n_eff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in power\n",
      "  \n",
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_frame.loc[:, 'mean_time_intervals_min'] = data_frame.apply(lambda row: np.mean(make_list_intervals_new(t_max, \n",
    "                                  row.time_step, \n",
    "                                  row.rate_growth,\n",
    "                                  Vb,\n",
    "                                  row.n_eff,\n",
    "                                  row.v_init_th,\n",
    "                                  row.origin_open_and_firing_rate\n",
    "                                 ))*60, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in double_scalars\n",
      "  \n",
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/scipy/integrate/quadpack.py:880: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  **opt)\n",
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/scipy/integrate/quadpack.py:880: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  **opt)\n",
      "/home/berger/.virtualenvs/synchrony_project/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "data_frame.loc[:, 'theoretical_mean_interval'] = data_frame.apply(lambda row: double_integrate_two_events(row.rate_growth,\n",
    "                                  row.v_init_th,\n",
    "                                  Vb,\n",
    "                                  row.n_eff,\n",
    "                                  row.origin_open_and_firing_rate,\n",
    "                                  t_max\n",
    "                                 )*60, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named dataset_time_traces in the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30330/1072100442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_time_intervals_cell_cycle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maverage_asynch_time_cell_cycle_simu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/synchrony_project/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/.virtualenvs/synchrony_project/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/synchrony_project/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/synchrony_project/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30330/1072100442.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_time_intervals_cell_cycle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maverage_asynch_time_cell_cycle_simu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_30330/3523863501.py\u001b[0m in \u001b[0;36maverage_asynch_time_cell_cycle_simu\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maverage_asynch_time_cell_cycle_simu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mdataframe_time_traces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset_time_traces'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mdataframe_division_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset_div_events'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mV_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe_division_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v_d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/synchrony_project/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0mauto_close\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_close\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         )\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/synchrony_project/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, key, where, start, stop, columns, iterator, chunksize, auto_close)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No object named {key} in the file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# create the storer and axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No object named dataset_time_traces in the file'"
     ]
    }
   ],
   "source": [
    "data_frame.loc[:, 'mean_time_intervals_cell_cycle'] = data_frame.apply(lambda row: average_asynch_time_cell_cycle_simu(row), axis = 1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average time and CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average initiation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "palette='BuPu'\n",
    "\n",
    "ylorbr = cm.get_cmap('BuPu', 100)\n",
    "\n",
    "x = ylorbr(np.linspace(0,1,10))\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.set(xlabel=r'$n_{\\rm eff}$', ylabel=r'$\\langle \\Delta t \\rangle$')\n",
    "# ax.plot(n_eff, mean_time_intervals_min, color='r', label='simple simulation')\n",
    "# ax.plot(n_eff, np.array(theoretical_mean_interval), color='b', label='theory')\n",
    "# ax.plot(n_eff, np.array(theoretical_mean_interval_v2), color='g', label='theory 2')\n",
    "\n",
    "# sorted_data_frame = \n",
    "\n",
    "# plt.plot(time,approx_open_prob, linestyle = 'dotted', color= color_list[counter])\n",
    "# plt.plot(time,approx_open_prob, linestyle = 'dotted', color= color_list[counter])\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='mean_time_intervals_min',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     dashes=[(4, 1), ''],\n",
    "#     markers=True,\n",
    "    color=x[3],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='theoretical_mean_interval',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[7],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "# sns.lineplot(\n",
    "#     x='n_eff', \n",
    "#     y='mean_time_intervals_cell_cycle',\n",
    "#     data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "# #     hue='Hill coefficients:',\n",
    "# #     hue='deactivation rate:',\n",
    "#     linestyle=\"-.\",\n",
    "#     markers=True,\n",
    "#     palette= palette,\n",
    "# #     style='theoretical_prediction',\n",
    "#     linewidth = 3.5,\n",
    "#     legend = False,\n",
    "#     ax=ax\n",
    "# );\n",
    "\n",
    "ax.margins(0)\n",
    "\n",
    "ax.axhline(y=4, color='grey', linestyle='dotted')\n",
    "ax.axhline(y=3, color='grey', linestyle='dotted')\n",
    "ax.axvline(x=29, color='grey', linestyle='dotted')\n",
    "ax.axvline(x=38, color='grey', linestyle='dotted')\n",
    "ax.set(ylim=(0, 13))\n",
    "# plt.legend()\n",
    "plt.savefig(file_path + '/mean_time_interval.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV from simple simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulations_CV(t_max, time_step, rate_growth, v_birth, firing_rate_0, hill_coeff_eff, crit_vol):\n",
    "    n_simu = 5000\n",
    "    list_v_init = []\n",
    "    time = np.arange(0, t_max, time_step)\n",
    "    volume = v_birth * np.exp(time * rate_growth)\n",
    "    probability = calculate_approx_opening_prob_of_time(time, rate_growth, v_birth, hill_coeff_eff, crit_vol)\n",
    "    for simu_i in range(0, n_simu):\n",
    "        for n_step in range(1, time.size): # start at one because 0 is the initial condition\n",
    "            if calculate_whether_initiate(firing_rate_0 * probability[n_step], time_step):\n",
    "                list_v_init.append(volume[n_step]*2)\n",
    "                break\n",
    "    return np.std(np.array(list_v_init))/ np.mean(np.array(list_v_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.loc[:, 'CV_simulation'] = data_frame.apply(lambda row: simulations_CV(t_max, \n",
    "                                  row.time_step, \n",
    "                                  row.rate_growth,\n",
    "                                  Vb,\n",
    "                                  row.origin_firing_rate,\n",
    "                                  row.n_eff,\n",
    "                                  row.v_init_th\n",
    "                                 ), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV from cell cycle simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CV(row):\n",
    "    data_frame_init = pd.read_hdf(row.path_dataset, key='dataset_init_events')\n",
    "    initiation_volumes = np.array(data_frame_init['v_init'])\n",
    "    return np.std(initiation_volumes)/np.mean(initiation_volumes)\n",
    "\n",
    "data_frame.loc[:, 'CV'] = data_frame.apply(lambda row: calculate_CV(row), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.loc[:, 'theoretical_CV'] = data_frame.apply(lambda row: calculate_CV_theoretical(row.rate_growth,\n",
    "                                  row.v_init_th,\n",
    "                                  Vb,\n",
    "                                  row.n_eff,\n",
    "                                  row.origin_open_and_firing_rate,\n",
    "                                  t_max\n",
    "                                 ), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "palette='BuPu'\n",
    "\n",
    "ylorbr = cm.get_cmap('BuPu', 100)\n",
    "\n",
    "x = ylorbr(np.linspace(0,1,10))\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.set(xlabel=r'$n_{\\rm eff}$', ylabel=r'CV')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='CV',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[4],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='CV_simulation',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[7],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='theoretical_CV',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[2],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "\n",
    "ax.margins(0)\n",
    "\n",
    "ax.axhline(y=0.048, color='grey', linestyle='dotted')\n",
    "ax.axhline(y=0.062, color='grey', linestyle='dotted')\n",
    "ax.axvline(x=29, color='grey', linestyle='dotted')\n",
    "ax.axvline(x=38, color='grey', linestyle='dotted')\n",
    "ax.set(ylim=(0, 0.2))\n",
    "# plt.legend()\n",
    "plt.savefig(file_path + '/CV.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot with two axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "palette='BuPu'\n",
    "\n",
    "ylorbr = cm.get_cmap('BuPu', 100)\n",
    "\n",
    "x = ylorbr(np.linspace(0,1,10))\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.set(xlabel=r'$n_{\\rm eff}$', ylabel=r'$\\langle \\Delta t \\rangle$ [min]')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='theoretical_mean_interval',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[7],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "ax.yaxis.label.set_color(x[7])\n",
    "ax.tick_params(axis='y', colors=x[7])\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='theoretical_CV',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[4],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax2\n",
    ");\n",
    "\n",
    "ax2.set(ylabel=r'CV')\n",
    "ax2.yaxis.label.set_color(x[4])\n",
    "ax2.tick_params(axis='y', colors=x[4])\n",
    "# ax2.set(ylim=(0, 0.2))\n",
    "ax2.set(ylim=(0, 0.16))\n",
    "\n",
    "ax.margins(0)\n",
    "\n",
    "ax.axhline(y=4, color=x[7], linestyle='dotted', alpha=0.5)\n",
    "ax.axhline(y=3, color=x[7], linestyle='dotted', alpha=0.5)\n",
    "ax.set_yticks([0, 2, 3, 4, 6, 8, 10, 12])\n",
    "ax.set_yticklabels([r'0',r'2', r'$\\langle \\Delta t_{\\rm exp} \\rangle$', r'$\\Delta t_{\\rm exp}^{\\rm max}$', '6', r'8', '10', '12'])\n",
    "# ax.fill_between(np.arange(np.amin(np.array(data_frame['n_eff'])),np.amin(np.array(data_frame['n_eff'])), np.array(data_frame['n_eff']).size) , 3, 4, color=x[7], linestyle='dotted', alpha=0.5)\n",
    "\n",
    "# ax2.axhline(y=0.05, color=x[4], linestyle='dotted', alpha=0.5)\n",
    "# ax2.axhline(y=0.07, color=x[4], linestyle='dotted', alpha=0.5)\n",
    "\n",
    "# ax.axvline(x=29, color='grey', linestyle='dotted')\n",
    "# ax.axvline(x=38, color='grey', linestyle='dotted')\n",
    "# ax.set(ylim=(0, 12))\n",
    "ax.axvline(x=20, color='grey', linestyle='dotted')\n",
    "ax.axvline(x=27, color='grey', linestyle='dotted')\n",
    "ax.set(ylim=(0, 10))\n",
    "# plt.legend()\n",
    "plt.savefig(file_path + '/mean_time_interval_CV.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fraction within 50 percent volume change (to compare to Elf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_fraction_within_50_pc_volume_change(v_division_average, v_birth_average, initiation_volumes):\n",
    "    print(v_birth_average)\n",
    "    print(np.mean(initiation_volumes))\n",
    "    delta_50 = 0.5 * (v_division_average-v_birth_average)    \n",
    "    vol_50_percent = initiation_volumes[(initiation_volumes > np.mean(initiation_volumes)- 0.5 * delta_50 ) & (initiation_volumes < np.mean(initiation_volumes)+ 0.5 * delta_50)]\n",
    "    return vol_50_percent.size/initiation_volumes.size\n",
    "\n",
    "def calculate_fraction_within_50_pc_volume_change_data_frame(row):\n",
    "    data_frame_init = pd.read_hdf(row.path_dataset, key='dataset_init_events')\n",
    "    initiation_volumes = np.array(data_frame_init['v_init'])\n",
    "    data_frame_division = pd.read_hdf(row.path_dataset, key='dataset_div_events')\n",
    "    v_birth_average = np.mean(np.array(data_frame_division['v_b']))\n",
    "    v_division_average = np.mean(np.array(data_frame_division['v_d']))\n",
    "    return calculate_fraction_within_50_pc_volume_change(v_division_average, v_birth_average, initiation_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.loc[:, 'fract_within_50_vol_change_cell_cycle'] = data_frame.apply(lambda row: calculate_fraction_within_50_pc_volume_change_data_frame(row), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulations_f_50(t_max, time_step, rate_growth, v_birth, firing_rate_0, hill_coeff_eff, crit_vol):\n",
    "    n_simu = 5000\n",
    "    list_v_init = []\n",
    "    time = np.arange(0, t_max, time_step)\n",
    "    volume = v_birth * np.exp(time * rate_growth)\n",
    "    probability = calculate_approx_opening_prob_of_time(time, rate_growth, v_birth, hill_coeff_eff, crit_vol)\n",
    "    for simu_i in range(0, n_simu):\n",
    "        for n_step in range(1, time.size): # start at one because 0 is the initial condition\n",
    "            if calculate_whether_initiate(firing_rate_0 * probability[n_step], time_step):\n",
    "                list_v_init.append(volume[n_step])\n",
    "                break\n",
    "    return calculate_fraction_within_50_pc_volume_change(2*v_birth, v_birth, np.array(list_v_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.loc[:, 'fract_within_50_vol_change'] = data_frame.apply(lambda row: simulations_f_50(t_max, \n",
    "                                  row.time_step, \n",
    "                                  row.rate_growth,\n",
    "                                  Vb,\n",
    "                                  row.origin_firing_rate,\n",
    "                                  row.n_eff,\n",
    "                                  row.v_init_th\n",
    "                                 ), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "palette='BuPu'\n",
    "\n",
    "ylorbr = cm.get_cmap('BuPu', 100)\n",
    "\n",
    "x = ylorbr(np.linspace(0,1,10))\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.set(xlabel=r'$n_{\\rm eff}$', ylabel=r'$f_{50}$')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='fract_within_50_vol_change_cell_cycle',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[7],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='fract_within_50_vol_change',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[4],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "ax.margins(0)\n",
    "\n",
    "ax.axhline(y=0.95, color='grey', linestyle='dotted')\n",
    "# ax.axhline(y=0.027, color='grey', linestyle='dotted')\n",
    "ax.axvline(x=29, color='grey', linestyle='dotted')\n",
    "ax.axvline(x=38, color='grey', linestyle='dotted')\n",
    "# ax.set(ylim=(0, 0.13))\n",
    "# plt.legend()\n",
    "plt.savefig(file_path + '/CV.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulations_mean(t_max, time_step, rate_growth, v_birth, firing_rate_0, hill_coeff_eff, crit_vol):\n",
    "    n_simu = 5000\n",
    "    list_v_init = []\n",
    "    time = np.arange(0, t_max, time_step)\n",
    "    volume = v_birth * np.exp(time * rate_growth)\n",
    "    probability = calculate_approx_opening_prob_of_time(time, rate_growth, v_birth, hill_coeff_eff, crit_vol)\n",
    "    for simu_i in range(0, n_simu):\n",
    "        for n_step in range(1, time.size): # start at one because 0 is the initial condition\n",
    "            if calculate_whether_initiate(firing_rate_0 * probability[n_step], time_step):\n",
    "                list_v_init.append(volume[n_step])\n",
    "                break\n",
    "    return np.mean(np.array(list_v_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.loc[:, 'mean_simulation'] = data_frame.apply(lambda row: simulations_mean(t_max, \n",
    "                                  row.time_step, \n",
    "                                  row.rate_growth,\n",
    "                                  row.v_birth_th/ row.n_ori_birth,\n",
    "                                  row.origin_firing_rate,\n",
    "                                  row.n_eff,\n",
    "                                  row.v_init_th\n",
    "                                 ), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waiting_time_dist_indef(time_, growth_rate_, effective_hill_coeff_, v_init_, V_b_, firing_rate_0_):\n",
    "    vol = V_b_ * np.exp(growth_rate_* time_)\n",
    "    prefactor = firing_rate_0_ * vol**effective_hill_coeff_ / (vol**effective_hill_coeff_ + v_init_**effective_hill_coeff_ )\n",
    "    return prefactor * calculate_survival_probability_indefinite(time_, \n",
    "                                                                 growth_rate_, \n",
    "                                                                 effective_hill_coeff_, \n",
    "                                                                 v_init_, \n",
    "                                                                 V_b_,\n",
    "                                                                 firing_rate_0_)\n",
    "\n",
    "def integrand_mean(time, growth_rate_, v_init_, V_b_, n_, rate):\n",
    "    return waiting_time_dist_indef(time, growth_rate_, n_, v_init_, V_b_, rate) * time\n",
    "\n",
    "def calculate_mean_theoretical(growth_rate_, v_init_, V_b_, n_, rate, t_d_):\n",
    "    result = integrate.quad(lambda x: integrand_mean(x, growth_rate_, v_init_, V_b_,n_, rate), 0, t_d_)\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.loc[:, 'theoretical_mean'] = data_frame.apply(lambda row: calculate_mean_theoretical(row.rate_growth,\n",
    "                                  row.v_init_th,\n",
    "                                  Vb,\n",
    "                                  row.n_eff,\n",
    "                                  row.origin_open_and_firing_rate,\n",
    "                                  t_max\n",
    "                                 )[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "palette='BuPu'\n",
    "\n",
    "ylorbr = cm.get_cmap('BuPu', 100)\n",
    "\n",
    "x = ylorbr(np.linspace(0,1,10))\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.set(xlabel=r'$n_{\\rm eff}$', ylabel=r'CV')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='mean_simulation',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[7],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "sns.lineplot(\n",
    "    x='n_eff', \n",
    "    y='theoretical_mean',\n",
    "    data=data_frame.sort_values(by=[\"hill_activation_potential\"], ascending=False),\n",
    "#     hue='Hill coefficients:',\n",
    "#     hue='deactivation rate:',\n",
    "#     linestyle=\"dashed\",\n",
    "#     markers=True,\n",
    "    color=x[4],\n",
    "#     style='theoretical_prediction',\n",
    "    linewidth = 3.5,\n",
    "    legend = False,\n",
    "    ax=ax\n",
    ");\n",
    "\n",
    "ax.margins(0)\n",
    "\n",
    "# ax.axhline(y=0.048, color='grey', linestyle='dotted')\n",
    "# ax.axhline(y=0.062, color='grey', linestyle='dotted')\n",
    "# ax.axvline(x=29, color='grey', linestyle='dotted')\n",
    "# ax.axvline(x=38, color='grey', linestyle='dotted')\n",
    "# ax.set(ylim=(0, 0.2))\n",
    "# plt.legend()\n",
    "plt.savefig(file_path + '/v_init_mean.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synchrony_project",
   "language": "python",
   "name": "synchrony_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
